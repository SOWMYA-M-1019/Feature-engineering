{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. What is a parameter?\n",
        "Ans: In machine learning, a parameter is an internal variable within a model that is learned from the data during training, and its values are adjusted to improve the model's performance.\n",
        "\n",
        "#2. What is correlation? What does negative correlation mean?\n",
        "Ans: Correlation describes the relationship between two or more variables. When two variables change in the same direction (both increasing or both decreasing), it's a positive correlation. A negative correlation, also known as an inverse correlation, means that as one variable increases, the other variable decreases, and vice versa.\n",
        "\n",
        "#3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "Ans: Machine learning (ML) is that enables computers to learn from data without being explicitly programmed. It involves algorithms and models that can improve with experience and data exposure.\n",
        "The main components of machine learning include data, algorithms, models, and .predictions.\n",
        "\n",
        "#4.How does loss value help in determining whether the model is good or not?\n",
        "Ans: A model's loss value indicates how accurate its predictions are, with lower values generally suggesting a better model. It quantifies the difference between the model's predictions and the actual values, and the goal of training is to minimize this loss.\n",
        "\n",
        "#5.What are continuous and categorical variables?\n",
        "Ans:In data analysis, variables are classified as either continuous or categorical. Continuous variables can take on any value within a given range, while categorical variables represent distinct groups or categories.\n",
        "\n",
        "#6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "Ans: Handling categorical variables in machine learning involves converting them into a numerical format that models can understand. Common techniques include one-hot encoding, label encoding, ordinal encoding, and frequency encoding, each with its strengths and weaknesses depending on the specific data and model.\n",
        "\n",
        "#7.What do you mean by training and testing a dataset?\n",
        "Ans: In machine learning, \"training\" a dataset means using it to teach a model to make predictions or decisions based on patterns within the data. \"Testing\" a dataset, on the other hand, involves evaluating the model's performance on unseen data to ensure it generalizes well and doesn't overfit to the training data.\n",
        "\n",
        "#8.What is sklearn.preprocessing?\n",
        "Ans:sklearn.preprocessing is a module in the scikit-learn library that provides a set of tools for transforming raw data into a format suitable for machine learning algorithms. This process is crucial because many algorithms perform better when data is standardized, scaled, or otherwise preprocessed.\n",
        "\n",
        "#9.What is a Test set?\n",
        "Ans: A test set is a portion of a dataset used to evaluate the performance of a machine learning model after it has been trained. It's separate from the training data and provides an unbiased assessment of how well the model generalizes to new, unseen data.\n",
        "\n",
        "#10.How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "Ans: In Python, data is typically split into training and testing sets using the train_test_split function from the sklearn.model_selection module. This allows you to train a model on a portion of the data and then evaluate its performance on unseen data, ensuring a more accurate assessment of how well the model generalizes to new examples. When approaching a Machine Learning problem, a systematic process is recommended, including data collection, preparation, model selection, training, evaluation, and potentially tuning.\n",
        "\n",
        "#11.Why do we have to perform EDA before fitting a model to the data?\n",
        "Ans:Exploratory Data Analysis (EDA) before model fitting is crucial for several reasons. It allows you to identify potential errors, outliers, and patterns in the data, which can significantly impact model performance and accuracy. EDA helps understand the data's structure and distributions, guiding feature selection and model choices, ultimately leading to a more robust and effective model.\n",
        "\n",
        "#12.What is correlation?\n",
        "Ans:In machine learning, correlation describes the extent to which two or more variables change together. It's a statistical measure that quantifies the strength and direction of their relationship, indicating how closely they move in sync. Correlation doesn't imply cause-and-effect, but it reveals how variables are related, which is crucial for building and interpreting machine learning models\n",
        "\n",
        "#13.What does negative correlation mean?\n",
        "Ans:A negative correlation, also known as an inverse correlation, means that as one variable increases, the other variable decreases, and vice versa. Essentially, the two variables move in opposite directions. This is represented by a downward-sloping straight line when plotted on a graph.\n",
        "\n",
        "#14.How can you find correlation between variables in Python?\n",
        "Ans:To find the correlation between variables in Python, several libraries and methods can be used:\n",
        "1. Pandas:\n",
        "The corr() method calculates the correlation matrix for a DataFrame, showing the relationships between all pairs of variables.\n",
        "By default, it calculates the Pearson correlation coefficient, which measures linear relationships.\n",
        "The corrwith() method can be used to compute the correlation between one column and all other columns in a DataFrame.\n",
        "2. NumPy:\n",
        "The corrcoef() function computes the correlation matrix between two or more arrays.\n",
        "3. SciPy:\n",
        "The pearsonr() function calculates the Pearson correlation coefficient between two variables, along with a p-value.\n",
        "The spearmanr() function calculates the Spearman rank-order correlation coefficient, which is suitable for non-linear relationships.\n",
        "The kendalltau() function calculates the Kendall tau correlation coefficient, another non-parametric measure.\n",
        "4. Visualization:\n",
        "Scatter Plots:\n",
        "Use matplotlib or seaborn to create scatter plots to visualize the relationship between two variables. This helps identify the type and strength of the correlation\n",
        "\n",
        "#15.What is causation? Explain difference between correlation and causation with an example.\n",
        "Ans:Causation means one event directly causes another, while correlation indicates a relationship between two events without implying one causes the other. Shiksha explains that causation always implies correlation, meaning if one event causes another, there's a relationship between them, but the reverse isn't true. For instance, if you strike a billiard ball with a cue stick, the cue stick hitting the ball causes it to move. However, if you observe that people who exercise more tend to be the people who get skin cancer, this doesn't mean exercise causes skin cancer. Instead, it's likely that both exercise and skin cancer are related to a third factor, such as increased exposure to sunlight.\n",
        "\n",
        "#16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "Ans: An optimizer is an algorithm that adjusts a model's parameters (like weights and biases) during training to minimize the loss function. It iteratively updates these parameters, aiming to find the best set of values that make the model's predictions most accurate.\n",
        "\n",
        "#17.What is sklearn.linear_model ?\n",
        "Ans:sklearn.linear_model is a module in the scikit-learn (sklearn) library, a popular Python library for machine learning. It provides a variety of linear models for regression and classification tasks. Linear models are used to find a linear relationship between the input features and the target variable.\n",
        "\n",
        "#18.What does model.fit() do? What arguments must be given?\n",
        "Ans:The model.fit() function is a fundamental method used in machine learning to train a model on a given dataset. It iteratively adjusts the model's internal parameters, such as weights and biases, to minimize a defined loss function. This process involves feeding the model with training data in batches, calculating the loss, and updating the parameters using optimization algorithms like gradient descent.\n",
        "\n",
        "#19.What does model.predict() do? What arguments must be given?\n",
        "Ans:model. predict() is used to generate predictions from the trained model based on new input data. It does not require true labels and does not compute any metrics.\n",
        "\n",
        "#20.What are continuous and categorical variables?\n",
        "Ans:In machine learning, continuous variables are numerical and can take any value within a given range, while categorical variables represent groups or categories. Continuous variables are measured and can be represented on a scale, while categorical variables are often non-numeric.\n",
        "\n",
        "#21.What is feature scaling? How does it help in Machine Learning?\n",
        "Ans: Feature scaling, also known as normalization or standardization, is a data preprocessing technique that transforms the values of numerical features in a dataset to a common scale or range. This is crucial in machine learning to ensure that features with different ranges or units don't disproportionately influence the model's performance.\n",
        "\n",
        "#22.How do we perform scaling in Python?\n",
        "Ans:Scaling in Python, often referred to as feature scaling, involves transforming numerical data to fit a specific range. This is crucial for many machine learning algorithms to perform optimally\n",
        "\n",
        "#23.What is sklearn.preprocessing?\n",
        "Ans:sklearn.preprocessing is a module in the scikit-learn library that provides a set of tools for transforming raw data into a format suitable for machine learning algorithms. This process is crucial because many algorithms perform better when data is standardized, scaled, or otherwise preprocessed.\n",
        "\n",
        "#24.How do we split data for model fitting (training and testing) in Python?\n",
        "Ans: In Python, data is typically split into training and testing sets using the train_test_split function from the sklearn.model_selection module. This function randomly divides the data into two subsets: a training set used to train the machine learning model, and a testing set used to evaluate its performance on unseen data.\n",
        "\n",
        "#25.Explain data encoding?\n",
        "Ans:Data encoding is the process of converting information from one form to another, often for efficient transmission, storage, or analysis. It essentially involves transforming data into a specific format that can be easily processed or understood by computers or other systems. ss"
      ],
      "metadata": {
        "id": "JxwWUn4y3dqg"
      }
    }
  ]
}